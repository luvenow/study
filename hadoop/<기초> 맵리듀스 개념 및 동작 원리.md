
## 맵리듀스

### 1. 서론
 
빅데이터를 처리하기 위한 과정의 일환으로 맵리듀스라는 강력한 패러다임이 자리잡은지 꽤 됐다. 맵리듀스는 2006년 구글이 발표한 빅테이블, 구글 파일 시스템(GFS) 등과 결합하며 아파치 재단 아래 '하둡' 이라는 이름의 프로젝트로 발주된다. 하둡에서 맵리듀스와 HDFS(Hadoop Distributed File System)이 합쳐 이전에 없던 강력한 시너지 효과를 발휘했다. 페타바이트급의 대용량, 즉 빅데이터를 처리할 수 있게 된 것이다. 간략하게 소개하자면, 큰 파일을 여러 작은 단위로 쪼갠 후 여러 머신(PC등)에 나눠 각 머신에서 쪼개진 파일을 처리하는 것이다.<br/><br/>

### 2. 맵리듀스의 원리

#### 2-1. Key + Value = Record
맵리듀스의 핵심은 **Key-Value** 쌍으로 데이터를 처리한다는 것이다. 예를 들어 다음과 같은 데이터를 가정해보자.

> <center>'개 - dog, 고양이 - cat'</center>

이 데이터는 한국어 - 영어 쌍을 갖는 데이터이다. 이를 맵리듀스에서는 다음과 같이 처리한다. 


> <center>　
> <b>key</b>　　　　　　　<b>value</b></center><br/>
> <center> 　　개　　　->　　　dog </center><br/>
> <center> 　고양이　　->　　　cat</center><br/>

개는 Key값이 되어 'dog'라는 value를 가리키고, 고양이는 'cat'이라는 value를 가리킨다. 간단하게 자료구조의 Map 형식으로 생각할 수 있다. 특정 한국어 단어(key)에 대응되는 영어 단어(value)가 쌍으로 존재하는 것이다. 이와 같이 맵리듀스는 Key-Value를 항상 한 쌍으로 처리한다. 이렇게 처리되는 **Key**와 **Value** 쌍을 하나의 **레코드**라 한다. <br/><br/>

#### 2-2. 맵리듀스 과정 및 설명
맵리듀스는 그 이름에서 알 수 있듯이 'Map'과 'Reduce' 작업으로 이루어져 있다. 그러나 작업이 정말로 맵과 리듀스만으로 이루어진 것은 아니다. 중간중간 맵리듀스 작업을 더욱 효율적으로 사용하기 위해서, 혹은 최적화하기 위해서 이루어지는 프로세스가 몇 개 존재한다. <br/>

(1) Input Data
말 그대로 입력 파일이다. 보통은 텍스트를 많이 처리하지만, 경우에 따라 이미지, 통계 자료 등 여러 가지가 맵리듀스의 입력 데이터가 될 수 있다. 이 입력 파일은 HDFS에 적재되어 병렬처리를 위해 여러 머신에 분배된다.<br/>

(2) Map
매퍼는 맵리듀스에서 Map 작업을 수행하는 객체이다. 일반적으로 텍스트 파일에서 개행을 기준으로 한 줄씩 읽어 입력 데이터를 원하는 Key-Value 형태로 만드는 작업이다. 사용자가 원하는 Key-Value 형태를 만들기 위해서는 직접 코딩해야한다. Key-Value 형태로 값을 얻었다면 결과 객체에 Key-Value를 insert한다. 매퍼는 입력 테이터의 크기에 따라서, 혹은 목적에 따라서 여러 개가 존재할 수 있다. <br/>

(3) Combiner
컴바이너는 네트워크의 병목현상(Bottle-Neck)을 줄일 수 있는 좋은 수단이다. 매퍼에서 출력된 Key-Value는 매우 난잡한 상황일 것임에 틀림없다. Key-Value를 하나로 뭉쳐 리듀서로 보낼 때 적은 양의 데이터를 보낼 수 있도록 한다. 예를 들어 어느 한 매퍼에서 나온 데이터가 아래와 같다고 가정하자.

> [사과, GreenApple] [바나나, Banana] [사과,  RedApple] [사과, YellowApple]

이 4개의 레코드를 리듀서에게 각각 보내기보다는 'Key'로 묶어어 보내면 전송되는 데ㅣ터의 양이 줄어들 것이다. 컴바이너는 위의 데이터를

> [사과, {GreenApple, RedApple, YellowApple}] [바나나, Banana]

로 합치는 역할을 한다. 중요한 것은 **'Key'**로 묶는다는 것이다. 정제되지 않은 4개의 레코드를 리듀서에게 전송하기보다는, 공통된 키로 묶어 2개의 레코드로 보내는 것이 더욱 효율적이다. 여기서는 4개의 레코드로 예시를 들었지만 실제로 작업을 할 때에는 어마어마하게 많은 Key-Value 쌍이 존재하기 때문에, 이 작업은 매우 중요하다. 각 매퍼에 하나의 컴바이너가 실행된다.
컴바이너는 대부분의 경우 사용자에 의해 커스터마이징된다. 간단한 맵리듀스거나, 컴바이너를 사용하지 못하는 맵리듀스일 때에는 커스터마이징하지 않는다.<br/>

(4) Suffle - Partitioner 작업
컴바이너에서 꾹꾹 담겨진 레코드들을 리듀서로 전송하는 일련의 과정을 **'셔플'**이라고 한다. 파티셔너도 셔플에 포함된다고 보면 편한데, 실제로 존재하는 객체는 셔플이 아닌 파티셔너이기 때문이다. 파티셔너는 각 매퍼에서 나온 출력 레코드들이 어느 리듀서로 가야할지를 정하는 작업이다. 위의 매퍼 설명에서 매퍼는 여러 개가 존재할 수 있다고 했는데, 매퍼 A와 B가 컴바이너를 거쳐서 나온 출력 레코드가 다음과 같다고 가정하자.

> 매퍼 A: [사과, {GreenApple, RedApple, YellowApple}] [바나나, Banana]<br/>
> 매퍼 B: [사과, {BlackApple}] [바나나, {Banana, GreenBanana}] [딸기, strawberry]

이제 위 데이터를 리듀서로 보내 처리를 해야하는데, 같은 키를 가지는 레코드들은 같은 리듀서에서 처리되어야만 한다. 그래야만 원하는 데이터를 얻어낼 수 있기 때문이다.  실제로 '사과'라는 키를 가지는 레코드는 매퍼 A,B 말고도 매퍼 C, D에서도 존재할 수 있다. 그럼 이들을 어떻게 하나의 리듀서로 보낼 수 있을까? <br/>
그 답은  '해시코드'이다. 사과라는 키를 해시코드로 바꾼 뒤, 리듀서의 갯수로 그 해시 코드를 나눠서 나온 나머지로 리듀서를 정한다. (리듀서 또한 사용자가 갯수를 지정할 수 있다. )  예를 들어 3개의 리듀서가 있다 가정했을 때,   '사과'라는 키에 대한 파티셔닝 작업을 살펴보자.<br/>

> <center><b>Key : '사과'</b></center><br/>
> <center><b>HashCode : 1453457</b></center><br/>
> <center><b>목적 리듀서 : HashCode % 3 = 2 </b></center>
>  <br/>
> <center><b>Mappers　　　　　　Reducers</b></center><br/>
> <center>　　A 　 　　　　　　　　　　 </center><br/>
> <center>　　B　　　　　　　　리듀서1</center><br/>
> <center>　　C　 　----------->　리듀서2</center><br/>
> <center>　　D　　　　　　　　리듀서3</center><br/>
> <center>　　E 　 　　　　　　　　　　 </center><br/>

키 값인 '사과' 가 1453457이라는 해시 값을 가질 때, 이를 리듀서의 개수 3으로 나눈 나머지인 '2'가 '사과' 레코드가 가야할 리듀서이다. 매퍼 A에서 나온 사과 레코드도, 매퍼 B에서 나온 사과 레코드도 그리고 나머지 매퍼에서 나오는 사과 레코드도 모두 리듀서2로 모이게 되므로 결국 모든 사과 레코드는 2번 리듀서에 모인다. 이것이 파티셔너가 하는 역할이다.<br/>

파티셔너는 커스터마이징할 수 있지만 보통 사용자가 직접 만질 일은 없다. 커스터마이징한다면 사용자 정의 객체를 키로 사용할 때 해시함수를 정의하는 정도이다. 단, 여기서 주의해야 할 것은 어떤 데이터가 어느 리듀서로 가게 될지는 아무도 모른다는 거이다.<br/>

(5) Sort
리듀서가 파티셔너로부터 레코드를 잘 받았다면, 리듀스 작업을 하기 전에 정렬이라는 전처리 작업을 수행한다. 리듀서에 도착한 레코드들을 키값을 기준으로 정렬한다. 이는 리듀스 작업을 용이하게 하기 위해서이다. 예시를 다시 들어보자. 위에서 든 예시에서 결국 2번 리듀서에 다음과 같은 레코드들이 도착했다고 가정하자. 정말 우연히도 바나나 레코드도 2번 리듀서에 도착했다.

> [사과, {GreenApple, RedApple, YellowApple}] [바나나, Banana] [사과, {BlackApple}] [바나나, {Banana, GreenBanana}]

키가 사과인 레코드와 바나나인 레코드가 뒤섞여있다. 동일한 키에 대해 동일한 작업을 수행하기 위해 정렬을 통해 동일한 키를 가지는 레코드들을 한 곳에 모은다. 그럼 리듀서 내부에서 다음과 같이 레코드들이 구성된다.

> <b>사과 그룹</b>: [사과, {GreenApple, RedApple, YellowApple}] [사과, {BlackApple}]<br/>
> <b>바나나 그룹</b>:  [바나나, Banana] [바나나, {Banana, GreenBanana}]

정렬은 리듀서 안에서 자동으로 일어나므로 보통 커스터마이징하지 않는다. 커스터마이징한다면 사용자 정의 객체를 키로 사용할 때 비교 함수를 정의하는 정도이다.<br/>

(6) Reduce
정렬을 통해 리듀서 내부에서 같은 키를 가지는 레코드들을 한 곳에 모았다면, 리듀스 함수에서 그 한 군데 모인 레코드들으르 순서대로 처리할 수 있다. 예를 들어 리듀스 함수 내부에서 다음과 같은 로직으로 키:사과에 대한 레코드들의 Value들을 출력할 수 있다. 출력 결과는 'GreenApple, RedApple, YellowApple' 이 될 것이다. 

> while(values.getNext())<br/>
> {<br/>
> 　　System.out.println(values.next().get();<br/>
> }

이 과정에서는 키에 따라 모인 레코드들의 Value로 사용자가 원하는 작업을 하도록 커스터마이징 작업을 거친다. 리듀서로 들어온 레코드들을 원하는 형태로 가공하여 결과 객체에 작성한 뒤 파일로 출력한다. 또한, 리듀서의 갯수를 사용자가 읨의로 설정할 수 있기에, 다른 리듀서에서는 다른 과일(ex 키:딸기) 에 대한 작업이 이루어지고 있을지도 모른다.

(7) Output
리듀서가 모든 작업을 끝내면 각 리듀서들은 처리한 레코드들을 파일로 출력한다. 각 리듀서마다 'part-r-....' 의 포맷으로 결과를 출력한다. 예를 들어 리듀서의 갯수가 3개라면 총 3개의 출력 파일 : part-r-00001, part-r-00002, part-r-00003이 있을 것이다.<br/>

---
### Reference
- [네이버 블로그](https://m.blog.naver.com/PostView.nhn?blogId=alice_k106&logNo=220462251435&proxyReferer=https%3A%2F%2Fm.blog.naver.com%2Ftwowinsh%2F221242463233#)


### Futher Reading
